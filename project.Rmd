---
title: "Predicting exercise performance based on temporal accelerometer data"
output: html_document
---

### Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, I analyze data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.


### Data cleaning

First I load the data set into R and do some cleaning.  The data set has 19622 rows and 162 columns.  The data set includes time trends for 153 physical activity variables for each of six individuals performing the exercise in five different ways.  Some activity variables are measured at all time points, while others are measured less frequently so have missing data for a large number of time points.

The classe variable indicates the type of exercise performance (A, B, C, D, or E).  I also create a variable, partclass, which indicates the participant and classe combination of a data point.  

```{r, message=FALSE}
library(caret) 
library(AppliedPredictiveModeling)
library(dplyr)
library(parallel)
library(doParallel)

wd = "~/Dropbox/data science notes/machine learning"
# "C:/Users/Gail/Dropbox/data science notes/machine learning"
setwd(wd)

dat = read.csv("pml-training.csv", na.strings=c("#DIV/0!", "(Other)", "", "NA"), strip.white=TRUE)
dat$partclass = paste(dat$user_name, dat$classe, sep=".")
categories = unique(dat$partclass)

## Combine two timestamp variables into a single timestamp
dat$timestamp = dat$raw_timestamp_part_1 + 
  100000*dat$raw_timestamp_part_2
sorted.dat = arrange(dat, partclass, timestamp)
```

The data set contains only six users, which is too small to divide into training and test sets.  I created my predictive model on the entire data set, and then used cross-validation to estimate out of sample error rates.  

I considered whether the variables may have time trends.  For each physical activity variable, I created a plot showing 30 time trends: one for each user/class combination.  The time trends are color-coded by class, but not by user, so for example 6 different red trends display the patterns generated by the six users for class A.  I examined these 153 plots individually.  I display only three of them for you to get a sense of the variety of patterns. 


```{r}
classes = unique(dat$classe)
users=unique(dat$user_name)
class.colors=rainbow(6)

for (j in c(8, 9, 110 )){
## calculate min and max ylim
user.index=1

ymin = min(dat[,j], na.rm=TRUE)
ymax = max(dat[,j], na.rm=TRUE)

class.index = 1
  plot(sorted.dat[sorted.dat$classe == classes[class.index] &
                    sorted.dat$user_name== users[user.index], j], 
       type="l", 
       col=class.colors[class.index],  ylim=c(ymin, ymax),
       main=paste(names(sorted.dat)[j]), ylab="")

for (class.index in 6:1){
  for (user.index in 1:6) {
      lines(sorted.dat[sorted.dat$classe == classes[class.index] &
                      sorted.dat$user_name== users[user.index], j], 
         col=class.colors[class.index],  ylim=c(ymin, ymax),
         main=names(sorted.dat), ylab="")
      }

    if (j<110) legend.location="bottomright" else legend.location="bottomleft"
    legend(legend.location, as.character(classes), col=class.colors, lty=1 , cex=.75, bg="white")
  }
}
```

None of the plots showed an apparent time trend, and I later discovered that the testing data included a single time point per observation rather than a time trend as an observation.  For this reason, I ignored the time variables in fitting my model.  Missing values were imputed to be the mean of the non-missing values for that variable for that user and classe combination.

```{r}
user_name=dat$user_name
classe=dat$classe
partclass=dat$partclass

## Remove columns with all missing values:
all.missing = (which(apply(is.na(dat), 2, sum)==nrow(dat)))
names.all.missing = names(dat)[all.missing]
dat=dat[, -all.missing]

for (j in 1:ncol(dat)){
  var = dat[,j]
  for (k in 1:30) {  
    if (sum(is.na(var[partclass == categories[k]] )) > 0 ) 
    dat[is.na(var) & partclass == categories[k], j] = 
        mean(var[partclass==partclass[k]], na.rm=TRUE)
  }
}
dat=dat[, 8:154]
```


### Predictive model

I use random forests to develop a predictive model, but the algorithm is quite time-consuming.  For this reason, in order to select variables to include, I create a random forest fit to a random subset of 1000 observations.  Then I used the varImp command to compute the importance of each predictor.  

```{r}
subsample = dat[sample(1:nrow(dat), size=1000),]
# 5:07
mod= train(classe~., data=subsample, method="rf", prox=TRUE)
imptce = varImp(mod)
hist(imptce$imp[,1], col="tomato", breaks=50,
     main="Importance of variables in predicting classe", xlab="importance")
```

I included all variables with importance of at least 4 in the final model, and used random forests to develop a predictive model.  I used parallelization to reduce computing time.

```{r}
important.predictors = which(imptce$imp[,1]>4)
newdat = dat[ , c(important.predictors, 147)]

registerDoParallel(clust <- makeForkCluster(detectCores()))
mod= randomForest(classe~., data=newdat)

stopCluster(clust)

pred=predict(mod, dat)
table(pred, dat$classe)
```

The classification works perfectly on the data used to create the model.

### Estimating out-of-sample accuracy

Next I use leave-one-out cross-validation to compute out-of-sample accuracy.

```{r, eval=FALSE}
users = unique(user_name)
predicted.classe=NULL

registerDoParallel(clust <- makeForkCluster(detectCores()))

for (k in 1:6){  ## Loop over 6 subjects
  
  ## Omit subject k; fit model using the other 5 subjects
  cvdat = newdat[user_name!=users[k], ] 
  cv.mod= randomForest(classe~., data=cvdat)
 
  ## Predict classe for subject k.
  predicted.classe[user_name == users[k]] = 
    predict(cv.mod, newdat[user_name == users[k], ])
}

stopCluster(clust)
registerDoSEQ()

predicted = levels(newdat$classe)[predicted.classe]
```

```{r, eval=FALSE}
table(newdat$classe, predicted)
mean(newdat$classe== predicted)
```

```{r, echo=FALSE}
setwd(wd)
load("newdat")
load("predicted")
table(newdat$classe, predicted)
mean(newdat$classe== predicted)
```


I estimate the out-of-sample prediction accuracy to be 37.7%.  If I had more time, I would preprocess the data more, by standardizing variables and using k-nearest neighbors for imputation.  

### Prediction on the test data set

Next I predict classe values for each of the test observations.  

```{r}
setwd(wd)
testing = read.csv("pml-testing.csv", 
    na.strings=c("#DIV/0!", "(Other)", "", "NA"), strip.white=TRUE)

dat$partclass = paste(dat$user_name, dat$classe, sep=".")

keep =  which(names(testing) %in% names(newdat))
testing=testing[,keep]
categories = unique(dat$partclass)
pred=predict(mod, testing)
answers = as.character(pred)

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)
```

